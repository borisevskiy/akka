## Почему современным системам нужна новая модель программирования

[Модель актора](https://ru.wikipedia.org/wiki/Модель_акторов) была предложена десятилетиями назад [Карлом Хьюиттом](https://en.wikipedia.org/wiki/Carl_Hewitt) 
как способ параллельной обработки в высокопроизводительной сети - среде, недоступной в то время. Сегодня аппаратные и 
инфраструктурные возможности догнали и превысили видение Хьюитта. Следовательно, организации, строящие распределенные 
системы с высокими требованиями, сталкиваются с проблемами, которые не могут быть полностью решены с помощью традиционной 
модели объектно-ориентированного программирования (ООП), но это может быть достигнуто при помощи модели актора.

Сегодня модель актора не только признана высокоэффективным решением - она доказана в производстве для некоторых из самых 
требовательных приложений в мире. Чтобы выделить проблемы, которые адресована моделью актора, в этом разделе обсуждаются 
следующие несоответствия между традиционными предположениями о программировании и реальностью современных многопоточных 
многопроцессорных архитектур.

### Проблема инкапсуляции

Основным элементом ООП является `инкапсуляция`. Инкапсуляция диктует, что внутренние данные объекта недоступны непосредственно 
извне; его можно изменить только путем вызова набора кураторских методов. Объект несет ответственность за раскрытие безопасных
 операций, которые защищают инвариантный характер его инкапсулированных данных.

_Например, операции над реализацией упорядоченного двоичного дерева не должны допускать нарушения инварианта упорядочения 
дерева. Клиенты `api` ожидают, что порядок будет неповрежденным, и при запросе дерева для определенной части данных они должны 
быть в состоянии полагаться на это ограничение._

Когда мы анализируем поведение времени выполнения ООП, мы иногда рисуем диаграмму последовательности сообщений, показывающую 
взаимодействие вызовов методов. Например:

![alt text](https://github.com/steklopod/akka/blob/akka_starter/src/main/resources/images/why-modern-systems-need-anew-programming-model/seq_chart.png "seq_chart")

К сожалению, приведенная выше диаграмма не точно отражает жизненные линии экземпляров во время выполнения. На самом деле 
поток выполняет все эти вызовы, а принудительное выполнение инвариантов происходит в том же потоке, из которого был вызван 
метод. Обновляя диаграмму потоком выполнения, она выглядит так:

![alt text](https://github.com/steklopod/akka/blob/akka_starter/src/main/resources/images/why-modern-systems-need-anew-programming-model/seq_chart_thread.png "seq_chart_thread")

Значение этого пояснения становится ясным, когда вы пытаетесь моделировать то, что происходит с несколькими потоками. 
Вдруг наша аккуратно нарисованная диаграмма становится неадекватной. Мы можем попытаться проиллюстрировать несколько потоков,
 обращаясь к одному экземпляру:
 
 ![alt text](https://github.com/steklopod/akka/blob/akka_starter/src/main/resources/images/why-modern-systems-need-anew-programming-model/seq_chart_multi_thread.png "seq_chart_multi_thread")

Существует **раздел выполнения**, в котором два потока вводят один и тот же метод. К сожалению, модель объектов инкапсуляции
 не гарантирует ничего о том, что происходит в этом разделе. Инструкции по двум вызовам могут чередоваться произвольными 
 способами, которые устраняют любую надежду на сохранение инвариантов без изменений без какой-либо координации между двумя 
 потоками. Теперь представьте, что этот вопрос усугубляется существованием множества потоков.

Общий подход к решению этой проблемы заключается в добавлении блокировки этих методов. Хотя это гарантирует, что не более 
одного потока будет вводить метод в любой момент времени, это очень дорогостоящая стратегия:

* Замки (`locks`) серьезно ограничивают параллелизм, они очень дорогостоящие на современных архитектурах процессоров, 
требующих тяжелого подъема из операционной системы, чтобы приостановить поток и восстановить его позже;

* Теперь поток вызывающий заблокирован, поэтому он не может выполнять какую-либо другую значимую работу. Даже в настольных 
приложениях это неприемлемо, поэтому мы хотим, чтобы пользовательские интерфейсы, зависящие от пользователя (его пользовательский
 интерфейс), реагировали даже при работе с длинным фоном. В бэкэнд блокировка полностью расточительна. Можно подумать, 
 что это может быть компенсировано пуском новых потоков, но потоки также являются дорогостоящей абстракцией;

* Замки представляют новую угрозу: дэдлоки.

Эти реалии приводят к неприятной ситуации:

* Без достаточных блокировок состояние становится поврежденным;

* Со многими замками на месте, производительность страдает и очень легко приводит к взаимоблокировкам.

Кроме того, шлюзы работают очень хорошо. Когда дело доходит до координации нескольких машин, единственной альтернативой 
являются распределенные блокировки. К сожалению, распределенные блокировки на несколько величин менее эффективны, чем 
локальные блокировки, и обычно налагают жесткий предел на масштабирование. Протоколы распределенных блокировок требуют 
нескольких обходов связи по сети через несколько компьютеров, поэтому латентность весьма увеличивается.

В объектно-ориентированных языках мы редко думаем о потоках или линейных путях выполнения в целом. Мы часто представляем 
систему как сеть экземпляров объектов, которые реагируют на вызовы методов, изменяют их внутреннее состояние, а затем 
общаются друг с другом посредством вызовов методов, ведущих вперед все состояние приложения:

 ![alt text](https://github.com/steklopod/akka/blob/akka_starter/src/main/resources/images/why-modern-systems-need-anew-programming-model/object_graph.png "object_graph")

Однако в многопоточной распределенной среде фактически происходит то, что потоки «пересекают» эту сеть экземпляров объектов, 
следуя вызовам метода. В результате потоки действительно приводят к выполнению:

 ![alt text](https://github.com/steklopod/akka/blob/akka_starter/src/main/resources/images/why-modern-systems-need-anew-programming-model/object_graph_snakes.png "object_graph_snakes")

> В итоге:

* **_Объекты могут гарантировать только инкапсуляцию (защиту инвариантов) перед однопоточным доступом, многопоточное 
выполнение почти всегда приводит к поврежденному внутреннему состоянию. Каждый инвариант может быть нарушен за счет наличия 
двух конкурирующих потоков в одном и том же сегменте кода;_**

* **_Хотя блокировки, по-видимому, являются естественным средством защиты инкапсуляции несколькими потоками, на практике 
они неэффективны и легко приводят к взаимоблокировкам при любом применении реального масштаба;_**

* **_Замки работают локально, попытки их распространения существуют, но предлагают ограниченный потенциал для масштабирования._**

## Иллюзия общей памяти на современных компьютерных архитектурах

Модели программирования 80-90-ых концептуализируют, что запись в переменную означает запись в ячейку памяти напрямую 
(_что несколько замалчивает, что локальные переменные могут существовать только в регистрах_). На современных архитектурах,
 если мы немного упростим, процессоры пишут [строки кэша](https://ru.wikipedia.org/wiki/Кэш_процессора), а не напрямую 
 записывают в память. Большинство этих кэшей  локальны для ядра процессора, то есть записи одним ядром не видны другим. 
 Чтобы сделать локальные изменения видимыми  для другого ядра и, следовательно, к другому потоку, строка кэша должна быть 
 отправлена ​​в кэш другого ядра.
 
В JVM мы должны явно указывать ячейки памяти, которые должны быть разделены между потоками, используя `volatile` маркеры или 
`Atomic`-обертки. В противном случае мы можем получить к ним доступ только в заблокированном разделе. Почему бы нам не 
отметить все переменные как изменчивые? Потому что строки кэширования доставки по всем ядрам - очень дорогостоящая операция! 
Это приведет к неявному завершению работы ядра при выполнении дополнительной работы и приведет к узким местам в протоколе
 когерентности кеша (используемые процессором протокола для передачи строк кэша между основной памятью и другими процессорами). 
 Результатом является замедление.

> В итоге:

* **Теперь нет реальной общей памяти, ядра CPU передают куски данных (строки кэша) явно друг другу, как это делают компьютеры 
в сети. Связь между процессорами и сетевая связь имеют больше общего, чем многие понимают. Передача сообщений является 
нормой в настоящее время через процессоры или сетевые компьютеры;**

* **Вместо того, чтобы скрывать аспекты передачи сообщения через переменные, помеченные как разделяемые или использующие 
атомные структуры данных, более дисциплинированный и принципиальный подход заключается в том, чтобы сохранить состояние 
локальным в параллельном объекте и передавать данные или события между параллельными объектами явно через сообщения.**

## Иллюзия стека вызовов

Сегодня мы часто принимаем стеки вызовов как должное. Но они были изобретены в эпоху, когда параллельное программирование 
было не так важно, потому что многопроцессорные системы не были обычным явлением. Стеки вызовов не пересекают потоки и, 
следовательно, не моделируют асинхронные цепочки вызовов.

Проблема возникает, когда поток намеревается делегировать задачу в «фоне». На практике это действительно означает делегирование 
другому потоку. Это не может быть простым вызовом метода/функции, потому что вызовы являются строго локальными для потока. 
Что обычно происходит, так это то, что «вызывающий» помещает объект в ячейку памяти, разделяемую рабочим потоком 
(«вызываемый»), который, в свою очередь, выбирает его в каком-то цикле событий. Это позволяет потоку «вызывающего» 
двигаться и выполнять другие задачи.

Первая проблема заключается в том, как можно «уведомить» о завершении задания? Но более серьезная проблема возникает, 
когда задача выходит из строя с исключением. Куда распространяется распространение этого исключения? Он будет 
распространяться на обработчик исключений рабочего потока, полностью игнорируя, кем был фактический «вызывающий»:

 ![alt text](https://github.com/steklopod/akka/blob/akka_starter/src/main/resources/images/why-modern-systems-need-anew-programming-model/exception_prop.png "exception_prop")

Это серьезная проблема. Как рабочий поток справляется с ситуацией? Вероятно, это не может решить проблему, поскольку она 
обычно не обращает внимания на цель неудавшейся задачи. Поток «вызывающего» должен быть уведомлен каким-то образом, но 
нет стека вызовов, чтобы справиться с исключением. Уведомление о сбое может выполняться только через боковой канал, 
например, для ввода кода ошибки, в котором поток «вызывающего» в противном случае ожидает результата после его завершения. 
Если это уведомление отсутствует, «вызывающий» никогда не получает уведомление об ошибке, и задача теряется! Это удивительно 
похоже на то, как сетевые системы работают там, где сообщения/запросы могут потеряться/отказать без какого-либо уведомления.

Эта плохая ситуация ухудшается, когда все идет по-настоящему неправильно, а работник, поддерживаемый потоком, 
сталкивается с ошибкой и попадает в неустранимую ситуацию. Например, внутреннее исключение, вызванное ошибкой, пузырится 
до корня потока и заставляет поток отключиться. Это немедленно поднимает вопрос, кто должен перезапустить обычную работу 
службы, размещенной в потоке, и как ее восстановить в известном состоянии? На первый взгляд это может показаться управляемым, 
но мы внезапно сталкиваемся с новыми неожиданными явлениями: фактическая задача, над которой работал текущий поток, больше 
не находится в области разделяемой памяти, где выполняются задачи (обычно это очередь ). Фактически, из-за исключения, 
достигающего вершины, разматывания всего стека вызовов, состояние задачи полностью потеряно! Мы потеряли сообщение, даже 
если это локальное общение без участия сети (где ожидаются сообщения).

> В итоге:

* Чтобы достичь значимого параллелизма и производительности в существующих системах, потоки должны делегировать задачи 
между собой эффективным образом без блокировки. Благодаря такому принципу делегирования задачи (и тем более с сетевыми/
распределенными вычислениями) обработка ошибок на основе стека на основе пакетов ломается, и необходимо вводить новые явные 
механизмы сигнализации ошибок. Неудачи становятся частью доменной модели;

* Параллельные системы с работой делегирования должны обрабатывать служебные ошибки и иметь принципиальные средства для 
восстановления от них. Клиенты таких служб должны знать, что задачи/сообщения могут потеряться во время перезапуска. 
Даже если потери не происходит, ответ может быть отложен произвольно из-за ранее заданных задач (длинная очередь), задержек, 
вызванных сбором мусора и т. Д. Ввиду этого параллельные системы должны обрабатывать сроки ответа в виде тайм-аутов, просто 
как сетевые/распределенные системы;

* Далее, давайте посмотрим, как использование модели актера может решить эти проблемы.

_Если этот проект окажется полезным тебе - нажми на кнопочку **`★`** в правом верхнем углу._

[<= содержание](https://github.com/steklopod/akka/blob/akka_starter/readme.md)